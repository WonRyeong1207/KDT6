{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### custom model learning\n",
    "- CNN, Vgg16 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import cnn_multi_class_func as cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset, val_dataset = cnn.make_dataset_cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.6863, -0.7333, -0.8275,  ..., -0.0667, -1.0000, -1.0000],\n",
       "          [-0.1137, -0.2706, -0.4980,  ...,  0.0118, -1.0000, -1.0000],\n",
       "          [-0.4510, -0.6157, -0.6706,  ...,  0.0510, -1.0000, -1.0000],\n",
       "          ...,\n",
       "          [-1.0000, -1.0000, -0.1608,  ...,  0.6314,  0.6157,  0.6078],\n",
       "          [-1.0000, -1.0000, -0.1451,  ...,  0.6078,  0.5843,  0.5843],\n",
       "          [-1.0000, -1.0000, -0.1373,  ..., -0.5059, -0.5137, -0.5137]],\n",
       " \n",
       "         [[-0.6706, -0.7098, -0.8039,  ..., -0.0745, -1.0000, -1.0000],\n",
       "          [-0.0510, -0.1922, -0.4118,  ...,  0.0118, -1.0000, -1.0000],\n",
       "          [-0.3882, -0.5451, -0.5843,  ...,  0.0510, -1.0000, -1.0000],\n",
       "          ...,\n",
       "          [-1.0000, -1.0000, -0.1373,  ...,  0.2784,  0.2392,  0.2157],\n",
       "          [-1.0000, -1.0000, -0.1216,  ...,  0.3020,  0.2549,  0.2314],\n",
       "          [-1.0000, -1.0000, -0.1137,  ..., -0.6000, -0.6157, -0.6235]],\n",
       " \n",
       "         [[-0.6392, -0.6784, -0.7647,  ..., -0.0431, -1.0000, -1.0000],\n",
       "          [ 0.0510, -0.0980, -0.2941,  ...,  0.0196, -1.0000, -1.0000],\n",
       "          [-0.2863, -0.4431, -0.4588,  ...,  0.0588, -1.0000, -1.0000],\n",
       "          ...,\n",
       "          [-1.0000, -1.0000, -0.1216,  ...,  0.2941,  0.2627,  0.2392],\n",
       "          [-1.0000, -1.0000, -0.1059,  ...,  0.2941,  0.2549,  0.2235],\n",
       "          [-1.0000, -1.0000, -0.0980,  ..., -0.6000, -0.6157, -0.6235]]]),\n",
       " 4)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataset: 23561\n",
      "val_dataset: 23561\n",
      "test_dataset: 2618\n"
     ]
    }
   ],
   "source": [
    "print(f\"train_dataset: {len(train_dataset.dataset)}\")\n",
    "print(f\"val_dataset: {len(val_dataset.dataset)}\")\n",
    "print(f\"test_dataset: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model = cnn.CustomVgg16MCModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomVgg16MCModel(\n",
      "  (vgg16): VGG(\n",
      "    (features): Sequential(\n",
      "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (3): ReLU(inplace=True)\n",
      "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (6): ReLU(inplace=True)\n",
      "      (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (8): ReLU(inplace=True)\n",
      "      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (11): ReLU(inplace=True)\n",
      "      (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (13): ReLU(inplace=True)\n",
      "      (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (15): ReLU(inplace=True)\n",
      "      (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (18): ReLU(inplace=True)\n",
      "      (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (20): ReLU(inplace=True)\n",
      "      (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (22): ReLU(inplace=True)\n",
      "      (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (25): ReLU(inplace=True)\n",
      "      (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (27): ReLU(inplace=True)\n",
      "      (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (29): ReLU(inplace=True)\n",
      "      (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "    (classifier): Sequential(\n",
      "      (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Dropout(p=0.5, inplace=False)\n",
      "      (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "      (4): ReLU(inplace=True)\n",
      "      (5): Dropout(p=0.5, inplace=False)\n",
      "      (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      "  (custom_layer): Sequential(\n",
      "    (0): ReLU()\n",
      "    (1): Linear(in_features=1000, out_features=500, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=500, out_features=50, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Linear(in_features=50, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "CustomVgg16MCModel                       --\n",
       "├─VGG: 1-1                               --\n",
       "│    └─Sequential: 2-1                   --\n",
       "│    │    └─Conv2d: 3-1                  1,792\n",
       "│    │    └─ReLU: 3-2                    --\n",
       "│    │    └─Conv2d: 3-3                  36,928\n",
       "│    │    └─ReLU: 3-4                    --\n",
       "│    │    └─MaxPool2d: 3-5               --\n",
       "│    │    └─Conv2d: 3-6                  73,856\n",
       "│    │    └─ReLU: 3-7                    --\n",
       "│    │    └─Conv2d: 3-8                  147,584\n",
       "│    │    └─ReLU: 3-9                    --\n",
       "│    │    └─MaxPool2d: 3-10              --\n",
       "│    │    └─Conv2d: 3-11                 295,168\n",
       "│    │    └─ReLU: 3-12                   --\n",
       "│    │    └─Conv2d: 3-13                 590,080\n",
       "│    │    └─ReLU: 3-14                   --\n",
       "│    │    └─Conv2d: 3-15                 590,080\n",
       "│    │    └─ReLU: 3-16                   --\n",
       "│    │    └─MaxPool2d: 3-17              --\n",
       "│    │    └─Conv2d: 3-18                 1,180,160\n",
       "│    │    └─ReLU: 3-19                   --\n",
       "│    │    └─Conv2d: 3-20                 2,359,808\n",
       "│    │    └─ReLU: 3-21                   --\n",
       "│    │    └─Conv2d: 3-22                 2,359,808\n",
       "│    │    └─ReLU: 3-23                   --\n",
       "│    │    └─MaxPool2d: 3-24              --\n",
       "│    │    └─Conv2d: 3-25                 2,359,808\n",
       "│    │    └─ReLU: 3-26                   --\n",
       "│    │    └─Conv2d: 3-27                 2,359,808\n",
       "│    │    └─ReLU: 3-28                   --\n",
       "│    │    └─Conv2d: 3-29                 2,359,808\n",
       "│    │    └─ReLU: 3-30                   --\n",
       "│    │    └─MaxPool2d: 3-31              --\n",
       "│    └─AdaptiveAvgPool2d: 2-2            --\n",
       "│    └─Sequential: 2-3                   --\n",
       "│    │    └─Linear: 3-32                 102,764,544\n",
       "│    │    └─ReLU: 3-33                   --\n",
       "│    │    └─Dropout: 3-34                --\n",
       "│    │    └─Linear: 3-35                 16,781,312\n",
       "│    │    └─ReLU: 3-36                   --\n",
       "│    │    └─Dropout: 3-37                --\n",
       "│    │    └─Linear: 3-38                 4,097,000\n",
       "├─Sequential: 1-2                        (recursive)\n",
       "│    └─Conv2d: 2-4                       (recursive)\n",
       "│    └─ReLU: 2-5                         --\n",
       "│    └─Conv2d: 2-6                       (recursive)\n",
       "│    └─ReLU: 2-7                         --\n",
       "│    └─MaxPool2d: 2-8                    --\n",
       "│    └─Conv2d: 2-9                       (recursive)\n",
       "│    └─ReLU: 2-10                        --\n",
       "│    └─Conv2d: 2-11                      (recursive)\n",
       "│    └─ReLU: 2-12                        --\n",
       "│    └─MaxPool2d: 2-13                   --\n",
       "│    └─Conv2d: 2-14                      (recursive)\n",
       "│    └─ReLU: 2-15                        --\n",
       "│    └─Conv2d: 2-16                      (recursive)\n",
       "│    └─ReLU: 2-17                        --\n",
       "│    └─Conv2d: 2-18                      (recursive)\n",
       "│    └─ReLU: 2-19                        --\n",
       "│    └─MaxPool2d: 2-20                   --\n",
       "│    └─Conv2d: 2-21                      (recursive)\n",
       "│    └─ReLU: 2-22                        --\n",
       "│    └─Conv2d: 2-23                      (recursive)\n",
       "│    └─ReLU: 2-24                        --\n",
       "│    └─Conv2d: 2-25                      (recursive)\n",
       "│    └─ReLU: 2-26                        --\n",
       "│    └─MaxPool2d: 2-27                   --\n",
       "│    └─Conv2d: 2-28                      (recursive)\n",
       "│    └─ReLU: 2-29                        --\n",
       "│    └─Conv2d: 2-30                      (recursive)\n",
       "│    └─ReLU: 2-31                        --\n",
       "│    └─Conv2d: 2-32                      (recursive)\n",
       "│    └─ReLU: 2-33                        --\n",
       "│    └─MaxPool2d: 2-34                   --\n",
       "├─AdaptiveAvgPool2d: 1-3                 --\n",
       "├─Sequential: 1-4                        (recursive)\n",
       "│    └─Linear: 2-35                      (recursive)\n",
       "│    └─ReLU: 2-36                        --\n",
       "│    └─Dropout: 2-37                     --\n",
       "│    └─Linear: 2-38                      (recursive)\n",
       "│    └─ReLU: 2-39                        --\n",
       "│    └─Dropout: 2-40                     --\n",
       "│    └─Linear: 2-41                      (recursive)\n",
       "├─Sequential: 1-5                        --\n",
       "│    └─ReLU: 2-42                        --\n",
       "│    └─Linear: 2-43                      500,500\n",
       "│    └─ReLU: 2-44                        --\n",
       "│    └─Linear: 2-45                      25,050\n",
       "│    └─ReLU: 2-46                        --\n",
       "│    └─Linear: 2-47                      510\n",
       "=================================================================\n",
       "Total params: 138,883,604\n",
       "Trainable params: 138,883,604\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(vgg_model)\n",
    "cnn.summary(vgg_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[vgg16.features.0.weight] - torch.Size([64, 3, 3, 3])\n",
      "[vgg16.features.0.bias] - torch.Size([64])\n",
      "[vgg16.features.2.weight] - torch.Size([64, 64, 3, 3])\n",
      "[vgg16.features.2.bias] - torch.Size([64])\n",
      "[vgg16.features.5.weight] - torch.Size([128, 64, 3, 3])\n",
      "[vgg16.features.5.bias] - torch.Size([128])\n",
      "[vgg16.features.7.weight] - torch.Size([128, 128, 3, 3])\n",
      "[vgg16.features.7.bias] - torch.Size([128])\n",
      "[vgg16.features.10.weight] - torch.Size([256, 128, 3, 3])\n",
      "[vgg16.features.10.bias] - torch.Size([256])\n",
      "[vgg16.features.12.weight] - torch.Size([256, 256, 3, 3])\n",
      "[vgg16.features.12.bias] - torch.Size([256])\n",
      "[vgg16.features.14.weight] - torch.Size([256, 256, 3, 3])\n",
      "[vgg16.features.14.bias] - torch.Size([256])\n",
      "[vgg16.features.17.weight] - torch.Size([512, 256, 3, 3])\n",
      "[vgg16.features.17.bias] - torch.Size([512])\n",
      "[vgg16.features.19.weight] - torch.Size([512, 512, 3, 3])\n",
      "[vgg16.features.19.bias] - torch.Size([512])\n",
      "[vgg16.features.21.weight] - torch.Size([512, 512, 3, 3])\n",
      "[vgg16.features.21.bias] - torch.Size([512])\n",
      "[vgg16.features.24.weight] - torch.Size([512, 512, 3, 3])\n",
      "[vgg16.features.24.bias] - torch.Size([512])\n",
      "[vgg16.features.26.weight] - torch.Size([512, 512, 3, 3])\n",
      "[vgg16.features.26.bias] - torch.Size([512])\n",
      "[vgg16.features.28.weight] - torch.Size([512, 512, 3, 3])\n",
      "[vgg16.features.28.bias] - torch.Size([512])\n",
      "[vgg16.classifier.0.weight] - torch.Size([4096, 25088])\n",
      "[vgg16.classifier.0.bias] - torch.Size([4096])\n",
      "[vgg16.classifier.3.weight] - torch.Size([4096, 4096])\n",
      "[vgg16.classifier.3.bias] - torch.Size([4096])\n",
      "[vgg16.classifier.6.weight] - torch.Size([1000, 4096])\n",
      "[vgg16.classifier.6.bias] - torch.Size([1000])\n",
      "[custom_layer.1.weight] - torch.Size([500, 1000])\n",
      "[custom_layer.1.bias] - torch.Size([500])\n",
      "[custom_layer.3.weight] - torch.Size([50, 500])\n",
      "[custom_layer.3.bias] - torch.Size([50])\n",
      "[custom_layer.5.weight] - torch.Size([10, 50])\n",
      "[custom_layer.5.bias] - torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for named, params in vgg_model.named_parameters():\n",
    "    print(f\"[{named}] - {params.shape}\")\n",
    "    params.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): ReLU()\n",
       "  (1): Linear(in_features=1000, out_features=500, bias=True)\n",
       "  (2): ReLU()\n",
       "  (3): Linear(in_features=500, out_features=50, bias=True)\n",
       "  (4): ReLU()\n",
       "  (5): Linear(in_features=50, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg_model.custom_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.weight] - torch.Size([500, 1000])\n",
      "[1.bias] - torch.Size([500])\n",
      "[3.weight] - torch.Size([50, 500])\n",
      "[3.bias] - torch.Size([50])\n",
      "[5.weight] - torch.Size([10, 50])\n",
      "[5.bias] - torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for named, params in vgg_model.custom_layer.named_parameters():\n",
    "    print(f\"[{named}] - {params.shape}\")\n",
    "    params.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "\"bincount_cpu\" not implemented for 'Float'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m loss_dict, acc_dict, f1_dict \u001b[38;5;241m=\u001b[39m \u001b[43mcnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvgg_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataset\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\PC\\Desktop\\AI_KDT6\\KDT6\\mini-project\\DeepLearning\\cnn_multi_class_func.py:705\u001b[0m, in \u001b[0;36mtraining\u001b[1;34m(model, train_datasets, val_datasets, epochs, lr, batch_size, patience)\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m    703\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m images, labels \u001b[38;5;129;01min\u001b[39;00m val_data_dl:\n\u001b[0;32m    704\u001b[0m         \u001b[38;5;66;03m# batch_cnt = len(val_datasets) / batch_size\u001b[39;00m\n\u001b[1;32m--> 705\u001b[0m         v_loss, v_acc, v_score, _ \u001b[38;5;241m=\u001b[39m \u001b[43mtesting\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    707\u001b[0m         total_v_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m v_loss\n\u001b[0;32m    708\u001b[0m         total_v_acc \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m v_acc\n",
      "File \u001b[1;32mc:\\Users\\PC\\Desktop\\AI_KDT6\\KDT6\\mini-project\\DeepLearning\\cnn_multi_class_func.py:654\u001b[0m, in \u001b[0;36mtesting\u001b[1;34m(model, test_images, test_labels)\u001b[0m\n\u001b[0;32m    652\u001b[0m     acc \u001b[38;5;241m=\u001b[39m MultilabelAccuracy(num_labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)(pred, test_labels)\n\u001b[0;32m    653\u001b[0m     f1 \u001b[38;5;241m=\u001b[39m MultilabelF1Score(num_labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)(pred, test_labels)\n\u001b[1;32m--> 654\u001b[0m     mat \u001b[38;5;241m=\u001b[39m \u001b[43mMultilabelConfusionMatrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    656\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss, acc, f1, mat\n",
      "File \u001b[1;32mc:\\Users\\PC\\anaconda3\\envs\\torch_cv_38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\PC\\anaconda3\\envs\\torch_cv_38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\PC\\anaconda3\\envs\\torch_cv_38\\lib\\site-packages\\torchmetrics\\metric.py:312\u001b[0m, in \u001b[0;36mMetric.forward\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    310\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_full_state_update(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 312\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_reduce_state_update\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    314\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_cache\n",
      "File \u001b[1;32mc:\\Users\\PC\\anaconda3\\envs\\torch_cv_38\\lib\\site-packages\\torchmetrics\\metric.py:381\u001b[0m, in \u001b[0;36mMetric._forward_reduce_state_update\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    378\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# allow grads for batch computation\u001b[39;00m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;66;03m# calculate batch state and compute batch value\u001b[39;00m\n\u001b[1;32m--> 381\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    382\u001b[0m batch_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute()\n\u001b[0;32m    384\u001b[0m \u001b[38;5;66;03m# reduce batch and global state\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\PC\\anaconda3\\envs\\torch_cv_38\\lib\\site-packages\\torchmetrics\\metric.py:493\u001b[0m, in \u001b[0;36mMetric._wrap_update.<locals>.wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    485\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected all tensors to be on\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(err):\n\u001b[0;32m    486\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    487\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered different devices in metric calculation (see stacktrace for details).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    488\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m This could be due to the metric class not being on the same device as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    491\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m device corresponds to the device of the input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    492\u001b[0m             ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m--> 493\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[0;32m    495\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_on_cpu:\n\u001b[0;32m    496\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_move_list_states_to_cpu()\n",
      "File \u001b[1;32mc:\\Users\\PC\\anaconda3\\envs\\torch_cv_38\\lib\\site-packages\\torchmetrics\\metric.py:483\u001b[0m, in \u001b[0;36mMetric._wrap_update.<locals>.wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    481\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_grad):\n\u001b[0;32m    482\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 483\u001b[0m         \u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    484\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    485\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected all tensors to be on\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(err):\n",
      "File \u001b[1;32mc:\\Users\\PC\\anaconda3\\envs\\torch_cv_38\\lib\\site-packages\\torchmetrics\\classification\\confusion_matrix.py:432\u001b[0m, in \u001b[0;36mMultilabelConfusionMatrix.update\u001b[1;34m(self, preds, target)\u001b[0m\n\u001b[0;32m    428\u001b[0m     _multilabel_confusion_matrix_tensor_validation(preds, target, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_labels, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mignore_index)\n\u001b[0;32m    429\u001b[0m preds, target \u001b[38;5;241m=\u001b[39m _multilabel_confusion_matrix_format(\n\u001b[0;32m    430\u001b[0m     preds, target, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_labels, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mthreshold, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mignore_index\n\u001b[0;32m    431\u001b[0m )\n\u001b[1;32m--> 432\u001b[0m confmat \u001b[38;5;241m=\u001b[39m \u001b[43m_multilabel_confusion_matrix_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    433\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfmat \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m confmat\n",
      "File \u001b[1;32mc:\\Users\\PC\\anaconda3\\envs\\torch_cv_38\\lib\\site-packages\\torchmetrics\\functional\\classification\\confusion_matrix.py:517\u001b[0m, in \u001b[0;36m_multilabel_confusion_matrix_update\u001b[1;34m(preds, target, num_labels)\u001b[0m\n\u001b[0;32m    515\u001b[0m unique_mapping \u001b[38;5;241m=\u001b[39m ((\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m target \u001b[38;5;241m+\u001b[39m preds) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m4\u001b[39m \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39marange(num_labels, device\u001b[38;5;241m=\u001b[39mpreds\u001b[38;5;241m.\u001b[39mdevice))\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[0;32m    516\u001b[0m unique_mapping \u001b[38;5;241m=\u001b[39m unique_mapping[unique_mapping \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m--> 517\u001b[0m bins \u001b[38;5;241m=\u001b[39m \u001b[43m_bincount\u001b[49m\u001b[43m(\u001b[49m\u001b[43munique_mapping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mminlength\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnum_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    518\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m bins\u001b[38;5;241m.\u001b[39mreshape(num_labels, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\PC\\anaconda3\\envs\\torch_cv_38\\lib\\site-packages\\torchmetrics\\utilities\\data.py:207\u001b[0m, in \u001b[0;36m_bincount\u001b[1;34m(x, minlength)\u001b[0m\n\u001b[0;32m    204\u001b[0m     mesh \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39marange(minlength, device\u001b[38;5;241m=\u001b[39mx\u001b[38;5;241m.\u001b[39mdevice)\u001b[38;5;241m.\u001b[39mrepeat(\u001b[38;5;28mlen\u001b[39m(x), \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    205\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39meq(x\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m), mesh)\u001b[38;5;241m.\u001b[39msum(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m--> 207\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbincount\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mminlength\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mminlength\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: \"bincount_cpu\" not implemented for 'Float'"
     ]
    }
   ],
   "source": [
    "loss_dict, acc_dict, f1_dict = cnn.training(vgg_model, train_dataset, val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.draw_two_plot(loss_dict, acc_dict, \"loss & accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_cv_38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
