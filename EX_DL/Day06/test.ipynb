{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DL TEST\n",
    "- kdt6 황지원"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 인공신경망을 구성하는 노드이다. 선형모델 기반으로 이루어져 다층으로 사용하면 비선형 문제도 해결 할 수 있다. 기본은 완전 연결의 모습을 하고 있지만 모델에 따라서는 듬성듬성 연결된 모습도 보인다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 퍼셉트론은 선형모델을 기반으로 하기 때문에 기본 수식이 y = ax + b와 동일하다. 그래서 input: 1, 2, 3, 4라면 각각의 가중치 w1, w2, w3, w4와 b 하나가 생긴다. 수식 output은 output = w1 * 1 + w2 * 2 + w3 * 3 + w4 * 4 + b이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 위와 같이 계산된 퍼셉트론의 결과 값을 확률 값으로 변환하기 위해 사용하는 함수이다. 초기에는 step 함수를 사용했지만 역전파에서 기울기 소실 문제를 해결하기 위해 다른 활성화 함수도 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. 활성화 함수의 종류\n",
    " - step function: 계단 모양의 함수로 초기 단층 퍼셉트론 모형에 많이 사용되었다. 값의 범위는 0과 1이며 0보다 작은 값은 0으로 0보다 크거나 같은 같은 1로 분류한다.\n",
    " - sigmoid: 역전파에서 step function의 기울기 소실 문제를 해결하기 위해서 각진 경계를 완만하게 만든 함수이다. 값의 범위는 0과 1이지만 step function과 다르게 완만하여 기울기 소실 문제를 조금이나마 해결할 수 있다.\n",
    " - ReLU: 언어모델에서 발생하는 기울기 소실 문제를 해결하기 위해 만들어진 활성화 함수이다. 값의 범위는 0부터 x이다. 0 이하의 값이 들어오면 0으로 0 보다 큰 값이 들어오면 들어온 값 그대로 반환한다.\n",
    " - Leaky ReLU: ReLU에서의 기울기 소실 문제를 해결하기 위해 제안된 함수이다. 0 이하의 값이 들어오면 0과 -1사이의 값으로 반환하고 나머지는 동일하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. 경사하강법은 모델에서 최적해를 찾아가는 알고리즘의 방법중 하나이다. 경사하강법은 loss function이 최저가 되는 지점을 찾는 방법인데 방향을 잘못 잡으면 발산하는 특징도 가지고 있다. 경사하강법의 계산 방법에는 모멘텀과 속도에 따라서 달라진다. 경사하강법의 종류에는 모멘텀, 확률적 경사하강법, Adam 등이 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. 기울기 소실이란 역전파 모델에서 가중치와 바이어스를 조정하면서 활성화 함수를 미분하게 되는데 이때 미분된 기울기 값이 너무 작아서 0에 수렴하는 현상을 말한다. 해결 방법으로는 노드나 층을 줄이거나 기울기가 완만한 활성화 함수를 사용하는 방법이 있다. 또 다른 방법으로는 노드간의 연결을 줄이는 방법이 있다. 계산량을 줄이는 방법이기에 역전파를 수행할때 미분을 적게하여 기울기 소실을 문제를 조금이나 해결할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. 파이토치의 모델 동작모드에는 model.train()과 model.evel()이 있다. 첫번째 모드는 모델을 학습 시키는 동작모드로 가중치와 바이어스의 역전파 계산과 업데이트가 이루어진다. 두번째 모드는 모델의 검증 모드로 첫번째 모드와는 다르데 가중치와 바이어스의 업데이트가 이루어지지 않는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optima"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. 회귀 모델 구현\n",
    "    - feature: 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.input = nn.Linear(3, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y = self.input(x)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. binary classification\n",
    "    - feature: 5\n",
    "    - class: 2\n",
    "    - layer: 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinayClf(nn.Module):\n",
    "    def __init__(self):\n",
    "        super.__init__()\n",
    "        \n",
    "        self.input_layer = nn.Linear(5, 15)\n",
    "        self.hidden_layer_1 = nn.Linear(15, 10)\n",
    "        self.hidden_layer_2 = nn.Linear(10, 5)\n",
    "        self.output_layer = nn.Linear(5, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y = F.relu(self.input_layer(x))\n",
    "        y = F.relu(self.hidden_layer_1(y))\n",
    "        y = F.relu(self.hidden_layer_2(y))\n",
    "        y = F.sigmoid(self.output_layer(y))\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. multi classification\n",
    "- feature: 5\n",
    "- class: 8\n",
    "- layer: 3 ~ 5\n",
    "- perceptron: dynamic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiClf(nn.Module):\n",
    "    def __init__(self, hidden_layer_num, hidden_perceptron_list):\n",
    "        super.__init__()\n",
    "        \n",
    "        self.input_layer = nn.Linear(5, hidden_perceptron_list[0])\n",
    "        self.hidden_layer = nn.ModuleList()\n",
    "        for i in range(hidden_layer_num):\n",
    "            self.hidden_layer.append(nn.Linear(hidden_perceptron_list[i], hidden_perceptron_list[i+1]))\n",
    "        self.output_layer = nn.Linear(hidden_perceptron_list[-1], 8)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y = F.relu(self.input_layer(x))\n",
    "        for layer in self.hidden_layer:\n",
    "            y = F.relu(layer(y))\n",
    "        y = self.output_layer(y)\n",
    "        return y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
