{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User Define Model Class\n",
    "- perents class: nn.Module\n",
    "- 필수 오버라이딩\n",
    "    - __init__(): 모델 층 구성, 전개\n",
    "    - forward(): 순방향 학습 진행 코드\n",
    " - 동적 모델\n",
    "    - container 모듈 둥 nn.ModuleList() 사용해서 동적으로 Layer 추가\n",
    "        - 연결이 안되어있다??\n",
    "        - Sequential은 연결되어있지만 저 친구는 아닌ㅁ\n",
    "        - forward 기능 미제공\n",
    "        - layer 어쩌구 저쩌구 나중에 기록하자..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optima\n",
    "\n",
    "from torchinfo import summary\n",
    "from torchmetrics.regression import R2Score, MeanSquaredError\n",
    "from torchmetrics.classification import F1Score, Accuracy, ConfusionMatrix\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(14)\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- basic create ANN model\n",
    "    - input layer: input node is len(feature)\n",
    "    - output layer: output node is len(label)\n",
    "    - hidden layer: fixed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- model structure\n",
    "    - datasets: feature dynamic, label dynamic, regression\n",
    "    - input layer   : input dynamic,   output dynamic,  activation function: ReLU, sigmoid (To solve gradient vanishing problem)\n",
    "    - hidden layer  : dynamic, activation function: ReLu, sigmoid\n",
    "    - output layer  : input dynamic, output dynamic,   activation function: None (마지막에는 확률값을 기반으로 결과를 도출하기에, 분류는 필요함. sigmoid, softmax)\n",
    "    - input, output, hidden 모든것이 동적, hidden perceptron도 동적"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- - -\n",
    "- 모델 이름: DynamicModel\n",
    "- 부모 class: nn.Module\n",
    "- parameter: in_in, out_out, h_in=[], h_outs=[]\n",
    "- - -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hidden layer가 동적인 모델\n",
    "class DynamicMyModel(nn.Module):\n",
    "    # callback function\n",
    "    def __init__(self, in_in, in_out, out_out, h_in=[], h_out=[]):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_layer = nn.Linear(in_in, h_in[0] if len(h_in) else in_out)\n",
    "        self.h_layers = nn.ModuleList()\n",
    "        for idx in range(len(h_in)):\n",
    "            self.h_layers.append(nn.Linear(h_in[idx], h_out[idx]))\n",
    "        # nn.ModuleList: 층을 동적으로 넣을때\n",
    "        self.output_layer = nn.Linear(h_out[-1] if len(h_out) else in_out, out_out)\n",
    "        \n",
    "    # forward learning\n",
    "    # callback funtion\n",
    "    # 전달인자: 학습용 데이터셋\n",
    "    def forward(self, x):\n",
    "        y = self.input_layer(x)\n",
    "        y = F.relu(y)\n",
    "        if len(self.h_layers):\n",
    "            for layer in self.h_layers:\n",
    "                y = layer(F.relu(y))\n",
    "        y = self.output_layer(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_in , h_out = [30, 50, 70], [50, 70, 30]\n",
    "model = DynamicMyModel(3, 5, 2, h_in, h_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DynamicMyModel(\n",
      "  (input_layer): Linear(in_features=3, out_features=30, bias=True)\n",
      "  (h_layers): ModuleList(\n",
      "    (0): Linear(in_features=30, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=70, bias=True)\n",
      "    (2): Linear(in_features=70, out_features=30, bias=True)\n",
      "  )\n",
      "  (output_layer): Linear(in_features=30, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "[input_layer.weight]\n",
      "Parameter containing:\n",
      "tensor([[-1.8903e-02,  1.4697e-01,  3.3553e-01],\n",
      "        [-4.2390e-01,  4.6174e-01, -4.1965e-01],\n",
      "        [ 5.1141e-03,  4.2055e-01, -2.7052e-01],\n",
      "        [-5.2810e-01,  5.6565e-01,  5.7650e-01],\n",
      "        [ 5.7447e-04,  1.7841e-01, -4.0783e-01],\n",
      "        [ 1.7680e-01,  4.8439e-01,  4.7958e-01],\n",
      "        [-4.4693e-01, -2.3760e-01, -5.7395e-01],\n",
      "        [ 2.5227e-01,  2.0006e-01, -3.5936e-01],\n",
      "        [ 2.4061e-01, -2.4257e-01, -4.2605e-01],\n",
      "        [ 4.2655e-01, -3.9283e-01, -4.3722e-01],\n",
      "        [-2.3995e-01,  2.7364e-01, -1.5960e-01],\n",
      "        [-4.9221e-01,  2.6890e-01,  1.1480e-01],\n",
      "        [ 6.1692e-02, -1.1377e-03,  1.8169e-01],\n",
      "        [ 2.5739e-01, -8.7531e-02,  1.4225e-01],\n",
      "        [ 3.7024e-02,  4.5197e-01,  5.1361e-01],\n",
      "        [-5.0452e-02, -4.7842e-01, -5.7319e-01],\n",
      "        [ 3.5337e-01, -1.8853e-01,  5.3774e-01],\n",
      "        [-5.6698e-01,  1.8441e-01, -4.9865e-01],\n",
      "        [ 4.3048e-02,  1.3654e-02, -3.8995e-01],\n",
      "        [-2.8376e-01,  3.7990e-01,  9.1445e-02],\n",
      "        [-4.4912e-01,  3.3702e-01,  5.5831e-01],\n",
      "        [-1.6514e-02,  3.0319e-01,  5.7479e-01],\n",
      "        [-3.9409e-01, -9.2390e-02,  3.5565e-01],\n",
      "        [ 5.6036e-01,  2.0950e-01, -4.9521e-01],\n",
      "        [ 8.8466e-02,  2.7412e-01,  5.5405e-01],\n",
      "        [-1.2961e-02, -1.7425e-01,  5.2131e-01],\n",
      "        [-1.4160e-01,  2.2812e-01,  2.3971e-02],\n",
      "        [ 3.2915e-01,  7.2895e-02, -2.5215e-01],\n",
      "        [ 1.1705e-02, -3.2231e-01,  1.7719e-01],\n",
      "        [ 5.4223e-01,  2.7905e-01, -3.0018e-01]], requires_grad=True)\n",
      "\n",
      "[input_layer.bias]\n",
      "Parameter containing:\n",
      "tensor([-0.4670, -0.4201,  0.0220,  0.5429,  0.3548, -0.2412, -0.1045, -0.4982,\n",
      "         0.1761, -0.0487, -0.1676, -0.4512,  0.3631,  0.0592,  0.0265, -0.2493,\n",
      "        -0.1699, -0.4319, -0.4971, -0.0805,  0.3859,  0.5558, -0.3107,  0.3282,\n",
      "        -0.4841, -0.3674, -0.2086,  0.5593,  0.2108,  0.1693],\n",
      "       requires_grad=True)\n",
      "\n",
      "[h_layers.0.weight]\n",
      "Parameter containing:\n",
      "tensor([[-0.1335, -0.0136, -0.0237,  ..., -0.1163,  0.0942, -0.0336],\n",
      "        [-0.0502,  0.0634, -0.0489,  ..., -0.1410, -0.0125, -0.1450],\n",
      "        [-0.0184, -0.1308, -0.0434,  ..., -0.1361, -0.0269, -0.1575],\n",
      "        ...,\n",
      "        [-0.1222,  0.0844, -0.0976,  ..., -0.0071, -0.0829,  0.0385],\n",
      "        [ 0.1387,  0.0724,  0.1600,  ..., -0.1754, -0.0975, -0.0634],\n",
      "        [-0.1040, -0.1313,  0.0526,  ..., -0.0864, -0.1393, -0.0602]],\n",
      "       requires_grad=True)\n",
      "\n",
      "[h_layers.0.bias]\n",
      "Parameter containing:\n",
      "tensor([ 0.0207,  0.0500, -0.0540,  0.0194, -0.1358,  0.1323,  0.0841, -0.0284,\n",
      "         0.1746,  0.1437, -0.0865,  0.1165,  0.1306,  0.0279,  0.1529,  0.0674,\n",
      "         0.1030,  0.0604,  0.0379,  0.1237, -0.1122,  0.0210, -0.1490, -0.1517,\n",
      "        -0.1823,  0.0924, -0.1544,  0.1242,  0.0307,  0.1661,  0.1679,  0.0220,\n",
      "         0.0652, -0.0401,  0.1360, -0.1159,  0.0077, -0.0334, -0.1077,  0.1316,\n",
      "         0.0155, -0.0976,  0.0818, -0.1238,  0.0281, -0.0989, -0.0434,  0.0864,\n",
      "         0.1684,  0.0763], requires_grad=True)\n",
      "\n",
      "[h_layers.1.weight]\n",
      "Parameter containing:\n",
      "tensor([[ 0.0806, -0.0813,  0.0279,  ..., -0.0584,  0.0241, -0.0289],\n",
      "        [ 0.1318, -0.0295,  0.0384,  ..., -0.0319,  0.0088, -0.1113],\n",
      "        [ 0.1278,  0.0677,  0.0605,  ...,  0.1309,  0.1011,  0.0349],\n",
      "        ...,\n",
      "        [ 0.1142,  0.0260,  0.0528,  ...,  0.0632, -0.0113, -0.1058],\n",
      "        [ 0.0866,  0.0723, -0.1098,  ..., -0.0675,  0.0506,  0.1009],\n",
      "        [ 0.1000, -0.1109, -0.1317,  ...,  0.0399, -0.0635, -0.0567]],\n",
      "       requires_grad=True)\n",
      "\n",
      "[h_layers.1.bias]\n",
      "Parameter containing:\n",
      "tensor([-0.0928, -0.1206,  0.0811, -0.1113,  0.0843,  0.1169,  0.1234, -0.1297,\n",
      "         0.0378,  0.1292,  0.0214,  0.0772,  0.0146, -0.0229, -0.0225,  0.1366,\n",
      "        -0.0725,  0.0610,  0.1242,  0.0844, -0.0230,  0.0651, -0.0240, -0.0127,\n",
      "         0.0164, -0.1093,  0.0160,  0.0888,  0.0624, -0.1097,  0.1208, -0.0218,\n",
      "         0.1264,  0.1277, -0.0785,  0.0664, -0.0218,  0.1080, -0.0075, -0.0752,\n",
      "        -0.0193,  0.0802, -0.0366, -0.1012,  0.0096,  0.1382,  0.0816,  0.0530,\n",
      "        -0.0719,  0.0847, -0.0259, -0.1388,  0.0962,  0.0241,  0.0248, -0.0420,\n",
      "         0.1295, -0.0827, -0.0914, -0.0603, -0.0828, -0.0656,  0.0741, -0.0254,\n",
      "        -0.0079, -0.0470,  0.0954, -0.0845, -0.1157,  0.0168],\n",
      "       requires_grad=True)\n",
      "\n",
      "[h_layers.2.weight]\n",
      "Parameter containing:\n",
      "tensor([[ 0.1175, -0.0551,  0.0495,  ...,  0.0383,  0.0885, -0.0553],\n",
      "        [ 0.1036, -0.0071,  0.0200,  ...,  0.1181,  0.0325, -0.0537],\n",
      "        [ 0.0782, -0.0732,  0.0950,  ...,  0.0491,  0.0082, -0.1146],\n",
      "        ...,\n",
      "        [ 0.0005, -0.0253, -0.0883,  ...,  0.0747, -0.0919,  0.0119],\n",
      "        [-0.1065,  0.0515,  0.0770,  ...,  0.0717, -0.0288, -0.0292],\n",
      "        [ 0.0344,  0.0582,  0.0063,  ...,  0.0937,  0.0237,  0.0022]],\n",
      "       requires_grad=True)\n",
      "\n",
      "[h_layers.2.bias]\n",
      "Parameter containing:\n",
      "tensor([ 0.0380, -0.0728,  0.0688,  0.0173, -0.0917,  0.0997, -0.0838, -0.0325,\n",
      "        -0.1025,  0.0249, -0.0835, -0.0742, -0.0451,  0.0791, -0.1132, -0.0076,\n",
      "        -0.0925,  0.0207, -0.0446,  0.0943,  0.0757,  0.0772,  0.0235, -0.0694,\n",
      "        -0.0937, -0.1066,  0.1001,  0.1037, -0.0329,  0.0278],\n",
      "       requires_grad=True)\n",
      "\n",
      "[output_layer.weight]\n",
      "Parameter containing:\n",
      "tensor([[-0.0823, -0.0393, -0.0164,  0.1049,  0.0234,  0.0856,  0.0017,  0.0283,\n",
      "         -0.0724,  0.1382, -0.0582,  0.0227,  0.0517, -0.1691, -0.1370, -0.0675,\n",
      "          0.1533,  0.1015, -0.1215, -0.0778,  0.1217, -0.0942,  0.0158,  0.0119,\n",
      "          0.1726, -0.0435,  0.0878,  0.1584,  0.1514,  0.1367],\n",
      "        [ 0.0918, -0.1823,  0.0997,  0.1241, -0.0440, -0.1262, -0.0940, -0.0618,\n",
      "          0.1004,  0.1111,  0.0966,  0.1378,  0.0815, -0.1106, -0.0776, -0.0577,\n",
      "          0.0519,  0.1609,  0.0359, -0.0902, -0.1415,  0.1554,  0.1738,  0.0808,\n",
      "          0.0175,  0.0489,  0.1187,  0.0138,  0.1705,  0.1342]],\n",
      "       requires_grad=True)\n",
      "\n",
      "[output_layer.bias]\n",
      "Parameter containing:\n",
      "tensor([ 0.0894, -0.1404], requires_grad=True)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(model, end='\\n\\n')\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"[{name}]\\n{param}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ts = torch.FloatTensor([[1, 3, 5], [2, 4, 6], [3, 5, 7], [4, 6, 8]])\n",
    "target_ts = torch.FloatTensor([[7, 9], [8, 10], [9, 11], [10, 18]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1247, -0.1213],\n",
      "        [ 0.1495, -0.0897],\n",
      "        [ 0.1737, -0.0582],\n",
      "        [ 0.1985, -0.0258]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y_pred = model(data_ts)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
