{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nature Language Processing Preprocessing -> Tokenization\n",
    "- Tokenization: 의미를 가진 최소 단위(형태소)로 나누는 작업\n",
    "    - word tokenize\n",
    "    - sent torkenize\n",
    "    - byte torkenize\n",
    "    - 종류는 다양함 'https://www.nltk.org/api/nltk.html' 여기서 필요한거 찾아서 보셈. 사이트 좀 별로임. 보기가 ㅈfkf이네"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Cleaning(정제)\n",
    "    - 토큰화 작업 전/후 tokenization에 방해되는 부분들은 제거\n",
    "    - 불용어 제거, 등장 빈도 기반 제거, 짧은 길이 단어 제거 등등\n",
    "        - 제거 전에 단어 확인하고 제거를 진행.\n",
    "        - 단어의 분포를 확인 해야함.\n",
    "            - 만약에 뉴스를 분석하는데 category가 경제인데 관련 단어들의 빈도가 낮을 수 있음.\n",
    "        - 불용어는 기본적으로 제거 후, 개발자가 custom으로 제거를 더 진행 해야함.\n",
    "    - 완벽한 정제는 어려움\n",
    "        - noise data: 분석 목적에 맞지 않는 데이터, 아무 의미를 가지지 않는 글씨들\n",
    "            (ex) ㅋㅋㅋㅋㅋㅋ, ㅜㅠㅜㅠㅜ, ㄴㄴ, ㅉ etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Stopword (불용어)\n",
    "    - 의미가 없는 word token을 제거하는 작업이 필요\n",
    "    - NKTL에는 100여개 이상의 영어 단어들을 불용어로 지정\n",
    "        - 불용어 리스트에 추가해야함. 개발자가 추가 해야합니다.\n",
    "        - 'ㅋㅋ'를 추가했다면 'ㅋㅋ'는 제거 되었는데 'ㅋㅋㅋ'는 남아있음... 하.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len english stopwords: 179\n",
      "english stopwords[:10]: ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]\n",
      "\n",
      "\n",
      "i me my myself we our ours ourselves you you're \n",
      "you've you'll you'd your yours yourself yourselves he him his \n",
      "himself she she's her hers herself it it's its itself \n",
      "they them their theirs themselves what which who whom this \n",
      "that that'll these those am is are was were be \n",
      "been being have has had having do does did doing \n",
      "a an the and but if or because as until \n",
      "while of at by for with about against between into \n",
      "through during before after above below to from up down \n",
      "in out on off over under again further then once \n",
      "here there when where why how all any both each \n",
      "few more most other some such no nor not only \n",
      "own same so than too very s t can will \n",
      "just don don't should should've now d ll m o \n",
      "re ve y ain aren aren't couldn couldn't didn didn't \n",
      "doesn doesn't hadn hadn't hasn hasn't haven haven't isn isn't \n",
      "ma mightn mightn't mustn mustn't needn needn't shan shan't shouldn \n",
      "shouldn't wasn wasn't weren weren't won won't wouldn wouldn't "
     ]
    }
   ],
   "source": [
    "# nltk 제공 영어\n",
    "english_stopwords = stopwords.words('english')\n",
    "\n",
    "print(f\"len english stopwords: {len(english_stopwords)}\")\n",
    "print(f'english stopwords[:10]: {english_stopwords[:10]}\\n')\n",
    "\n",
    "\n",
    "for i in range(len(english_stopwords)):\n",
    "    if i%10 == 0:\n",
    "        print()\n",
    "    print(english_stopwords[i], end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"He is loved game. He looks like caterpillar, in 'Alice's in Wonderlend'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "punctuation - ! : He is loved game. He looks like caterpillar, in 'Alice's in Wonderlend'\n",
      "punctuation - \" : He is loved game. He looks like caterpillar, in 'Alice's in Wonderlend'\n",
      "punctuation - # : He is loved game. He looks like caterpillar, in 'Alice's in Wonderlend'\n",
      "punctuation - $ : He is loved game. He looks like caterpillar, in 'Alice's in Wonderlend'\n",
      "punctuation - % : He is loved game. He looks like caterpillar, in 'Alice's in Wonderlend'\n",
      "punctuation - & : He is loved game. He looks like caterpillar, in 'Alice's in Wonderlend'\n",
      "punctuation - ' : He is loved game. He looks like caterpillar, in  Alice s in Wonderlend \n",
      "punctuation - ( : He is loved game. He looks like caterpillar, in  Alice s in Wonderlend \n",
      "punctuation - ) : He is loved game. He looks like caterpillar, in  Alice s in Wonderlend \n",
      "punctuation - * : He is loved game. He looks like caterpillar, in  Alice s in Wonderlend \n",
      "punctuation - + : He is loved game. He looks like caterpillar, in  Alice s in Wonderlend \n",
      "punctuation - , : He is loved game. He looks like caterpillar  in  Alice s in Wonderlend \n",
      "punctuation - - : He is loved game. He looks like caterpillar  in  Alice s in Wonderlend \n",
      "punctuation - . : He is loved game  He looks like caterpillar  in  Alice s in Wonderlend \n",
      "punctuation - / : He is loved game  He looks like caterpillar  in  Alice s in Wonderlend \n",
      "punctuation - : : He is loved game  He looks like caterpillar  in  Alice s in Wonderlend \n",
      "punctuation - ; : He is loved game  He looks like caterpillar  in  Alice s in Wonderlend \n",
      "punctuation - < : He is loved game  He looks like caterpillar  in  Alice s in Wonderlend \n",
      "punctuation - = : He is loved game  He looks like caterpillar  in  Alice s in Wonderlend \n",
      "punctuation - > : He is loved game  He looks like caterpillar  in  Alice s in Wonderlend \n",
      "punctuation - ? : He is loved game  He looks like caterpillar  in  Alice s in Wonderlend \n",
      "punctuation - @ : He is loved game  He looks like caterpillar  in  Alice s in Wonderlend \n",
      "punctuation - [ : He is loved game  He looks like caterpillar  in  Alice s in Wonderlend \n",
      "punctuation - \\ : He is loved game  He looks like caterpillar  in  Alice s in Wonderlend \n",
      "punctuation - ] : He is loved game  He looks like caterpillar  in  Alice s in Wonderlend \n",
      "punctuation - ^ : He is loved game  He looks like caterpillar  in  Alice s in Wonderlend \n",
      "punctuation - _ : He is loved game  He looks like caterpillar  in  Alice s in Wonderlend \n",
      "punctuation - ` : He is loved game  He looks like caterpillar  in  Alice s in Wonderlend \n",
      "punctuation - { : He is loved game  He looks like caterpillar  in  Alice s in Wonderlend \n",
      "punctuation - | : He is loved game  He looks like caterpillar  in  Alice s in Wonderlend \n",
      "punctuation - } : He is loved game  He looks like caterpillar  in  Alice s in Wonderlend \n",
      "punctuation - ~ : He is loved game  He looks like caterpillar  in  Alice s in Wonderlend \n"
     ]
    }
   ],
   "source": [
    "# 구두점 & 특수문자 제거\n",
    "punct = string.punctuation\n",
    "for pun in punct:\n",
    "    # print(f\"punctuation: {pun}\")\n",
    "    text = text.replace(pun, ' ')\n",
    "    print(f\"punctuation - {pun} : {text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before lower: he is loved game  he looks like caterpillar  in  alice s in wonderlend \n",
      "after lower: he is loved game  he looks like caterpillar  in  alice s in wonderlend \n",
      "\n",
      "tokens: ['he', 'is', 'loved', 'game', 'he', 'looks', 'like', 'caterpillar', 'in', 'alice', 's', 'in', 'wonderlend']\n",
      "\n",
      "after delate stopwords: ['is', 'loved', 'game', 'looks', 'like', 'caterpillar', 'alice', 'in', 'wonderlend']\n",
      "\n",
      "one more delate stopwords: ['loved', 'game', 'looks', 'like', 'caterpillar', 'alice', 'wonderlend']\n",
      "method hyojunsama: ['loved', 'game', 'looks', 'like', 'caterpillar', 'alice', 'wonderlend']\n"
     ]
    }
   ],
   "source": [
    "# 대/소문자 통일 in english field\n",
    "print(f\"before lower: {text}\")\n",
    "text = text.lower()\n",
    "print(f\"after lower: {text}\\n\")\n",
    "\n",
    "tokens = word_tokenize(text)\n",
    "print(f'tokens: {tokens}\\n')\n",
    "\n",
    "# if token is in english_stopwords, it delate\n",
    "# 원하는 문자가 제거가 되지 않았다면 stopwords.append 해주면 됨\n",
    "# I want to delete 'is'\n",
    "# english_stopwords.append('is')\n",
    "# 근데 있는데 안지워졌음... 왜? 'in'도 안지워졌네...\n",
    "\n",
    "# 효준사마의 방법\n",
    "ap_tokens = []\n",
    "for token in tokens:\n",
    "    if not token in english_stopwords:\n",
    "        ap_tokens.append(token) # stopwords가 연달아 있는 경우에는 remove하면 index number가 달라지기때문\n",
    "\n",
    "for token in tokens:\n",
    "    if token in english_stopwords:  \n",
    "        tokens.remove(token)\n",
    "    # 구두점을 처음에 제거하지 않았다면\n",
    "    if token in list(punct):\n",
    "        tokens.remove(token)\n",
    "        \n",
    "print(f\"after delate stopwords: {tokens}\\n\")\n",
    "        \n",
    "# 한번더 하면 지워지려나\n",
    "for token in tokens:\n",
    "    if token in english_stopwords:\n",
    "        tokens.remove(token)\n",
    "        \n",
    "print(f\"one more delate stopwords: {tokens}\")   # 이거 순서가 참... 허허 어이 없네\n",
    "print(f\"method hyojunsama: {ap_tokens}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 정규식 (regular expression)... 공부하는것이 과제\n",
    "    - 그나마 happy happy 한 정신건강과 전처리를 위해서 하는 편을 추천 ^^;;\n",
    "    - ㅠㅜㅠㅜㅠㅜㅠㅜㅠ\n",
    "    - 특별한 의미를 가지는 메타 문자\n",
    "        - `.`, `^`, `$`, `*`, `+`, `?`, `{ }`, `[ ]`, `|`, `( )`\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_38_018",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
